---
title: Running an OP Mainnet Node from Source
lang: en-US
description: Learn how to run an OP Mainnet node from source code.
---

import { Callout, Steps } from 'nextra/components'

# Running an OP Mainnet Node from Source

This tutorial explains how to run an OP Mainnet node from source code.
Running an OP Mainnet node from source code is a flexible alternative to using pre-built Docker images.

## Building the Source Code

You'll need to build `op-node` and `op-geth` from their respective source repositories before you can run a node.
Make sure to follow the instructions on [Building a Node from Source](./node-from-source) before continuing.

## Hardware Requirements

Hardware requirements for OP Mainnet nodes can vary depending on the type of node you plan to run.
Archive nodes generally require significantly more resources than full nodes.
Below are suggested minimum hardware requirements for each type of node.

*   16GB RAM
*   1TB SSD (full node) or 2TB SSD (archive node)
*   Reasonably modern CPU

## Get the Migrated Data Directory

OP Mainnet underwent a large database migration as part of the [Bedrock Upgrade](https://blog.oplabs.co/introducing-optimism-bedrock/) in 2023.
You will need access to the migrated OP Mainnet database to run a node.
You can [migrate your own data directory](https://blog.oplabs.co/reproduce-bedrock-migration/) or simply download database that has already been migrated.
In this section, you'll learn how to download and verify the pre-migrated database.

<Steps>
  {<h3>Download the Migrated Data Directory</h3>}

  Click the link below to download the latest publicly available database snapshot for OP Mainnet.
  This is a large file (325GB), so expect the download to take some time to complete.

  [OP Mainnet Migrated Data Directory (325GB)](https://datadirs.optimism.io/mainnet-bedrock.tar.zst)

  {<h3>Verify the Download</h3>}

  You should always verify the integrity of your downloads to ensure that they have not been corrupted.
  A corrupted database can include invalid data or may cause your node to fail.
  Verify the integrity of the download by checking the SHA512 checksum of the downloaded file.

  ```bash
  sha512sum mainnet-bedrock.tar.zst
  ```

  You should see the following output:

  ```bash
  c17067b7bc39a6daa14f71d448c6fa0477834c3e68a25e96f26fe849c12a09bffe510e96f7eacdef19e93e3167d15250f807d252dd6f6f9053d0e4457c73d5fb mainnet-bedrock.tar.zst
  ```

  If you see a different output, then the download is corrupted and you should try downloading the file again.

  {<h3>Extract the Data Directory</h3>}

  Once you've downloaded the database snapshot, you'll need to extract it to a directory on your machine.
  This will take some time to complete.

  ```bash
  tar xvf mainnet-bedrock.tar.zst
  ```
</Steps>

## Get the Legacy Geth Directory (Optional)

Blocks and transactions included in OP Mainnet before the Bedrock Upgrade cannot be executed by modern OP Mainnet nodes.
OP Mainnet nodes will **serve** these blocks and transactions but cannot run certain queries against them (e.g. `eth_call`).
If you need to run stateful queries like `eth_call` against these older blocks and transactions, you will need to run a Legacy Geth node alongside your OP Mainnet node.

Running a Legacy Geth node is entirely optional and typically only useful for operators who want to run complete archive nodes of the OP Mainnet state.
If you want to run a full node then you can safely skip this section.

<Steps>
  {<h3>Download the Legacy Geth Data Directory</h3>}

  Click the link below to download the latest publicly available database snapshot for Legacy Geth.
  This is a very large file (2.9TB), so expect the download to take some time to complete.

  [Legacy Geth Data Directory (2.9TB)](https://datadirs.optimism.io/mainnet-legacy-archival.tar.zst)

  {<h3>Verify the Download</h3>}

  You should always verify the integrity of your downloads to ensure that they have not been corrupted.
  A corrupted database can include invalid data or may cause your node to fail.
  Verify the integrity of the download by checking the SHA512 checksum of the downloaded file.

  ```bash
  sha512sum mainnet-legacy-archival.tar.zst
  ```

  You should see the following output:

  ```bash
  e348488c458baa755510f23bbc8601619bc66bea78a89354c949ba7be3c6b39ed7dd2c50516621e38df6120299407da0d24445b96bf94a50364ed07bb8234b26 mainnet-legacy-archival.tar.zst
  ```

  If you see a different output, then the download is corrupted and you should try downloading the file again.

  {<h3>Extract the Data Directory</h3>}

  Once you've downloaded the database snapshot, you'll need to extract it to a directory on your machine.
  This will take some time to complete.

  ```bash
  tar xvf mainnet-legacy-archival.tar.zst
  ```
</Steps>

## Start Legacy Geth (Optional)

If you've chosen to run a Legacy Geth node alongside your OP Mainnet node, you'll need to start it before you start your OP Mainnet node.

<Steps>
  {<h3>Navigate to your Legacy Geth directory</h3>}

  Find the directory where you built the `l2geth` binary.

  {<h3>Start l2geth</h3>}

  Run the following command to start `l2geth`:

  ```bash
  USING_OVM=true \
    ETH1_SYNC_SERVICE_ENABLE=false \
    RPC_API=eth,rollup,net,web3,debug \
    RPC_ENABLE=true \
    RPC_PORT=8546 \
    ./build/bin/geth --datadir /path/to/l2geth-datadir
  ```
</Steps>

## Create a JWT Secret

`op-geth` and `op-node` communicate over the engine API authrpc.
This communication is secured using a shared secret.
You will need to generate a shared secret and provide it to both `op-geth` and `op-node` when you start them.
In this case, the secret takes the form of a 32 byte hex string.

Run the following command to generate a random 32 byte hex string:

```bash
openssl rand -hex 32 > jwt.txt
```

## Start `op-geth`

It's generally easier to start `op-geth` before starting `op-node`.
You can still start `op-geth` without yet running `op-node`, but the `op-geth` instance will simply not receive any blocks until `op-node` is started.

<Steps>
  {<h3>Navigate to your op-geth directory</h3>}

  Find the directory where you built the `op-geth` binary.

  {<h3>Copy in the JWT secret</h3>}

  Copy the JWT secret you generated in a previous step into the `op-geth` directory.

  ```bash
  cp /path/to/jwt.txt .
  ```

  {<h3>Set environment variables</h3>}

  Set the following environment variables:

  ```bash
  export DATADIR_PATH=... # Path to the migrated data directory
  ```

  {<h3>Start op-geth</h3>}

  Use the following command to start `op-geth` in a default configuration.
  The JSON-RPC API will become available on port 8545.
  Refer to the `op-geth` [configuration documentation](../management/configuration#op-geth) for more detailed information about available options.

  ```bash
  ./build/bin/geth \
    --http \
    --http.port=8545 \
    --http.addr=0.0.0.0 \
    --authrpc.addr=localhost \
    --authrpc.jwtsecret=./jwt.txt \
    --verbosity=3 \
    --rollup.sequencerhttp=https://mainnet-sequencer.optimism.io/ \
    --nodiscover \
    --syncmode=full \
    --maxpeers=0 \
    --op-network=op-mainnet \
    --datadir=$DATADIR_PATH
  ```
</Steps>

## Start `op-node`

Once you've started `op-geth`, you can start `op-node`.
`op-node` will connect to `op-geth` and begin synchronizing the OP Mainnet state.
`op-node` will begin sending block payloads to `op-geth` when it derives enough blocks from Ethereum.

<Steps>
  {<h3>Navigate to your op-node directory</h3>}

  Find the directory where you built the `op-node` binary.

  {<h3>Copy in the JWT secret</h3>}

  Both `op-geth` and `op-node` need to use the same JWT secret.
  Copy the JWT secret you generated in a previous step into the `op-node` directory.

  ```bash
  cp /path/to/jwt.txt .
  ```

  {<h3>Set environment variables</h3>}

  Set the following environment variables:

  ```bash
  export L1_RPC_URL=...  # URL for the L1 node to sync from
  export L1_RPC_KIND=... # RPC type (alchemy, quicknode, infura, parity, nethermind, debug_geth, erigon, basic, any)
  ```

  {<h3>Start op-node</h3>}

  Use the following command to start `op-node` in a default configuration.
  Refer to the `op-node` [configuration documentation](../management/configuration#op-node) for more detailed information about available options.

  ```bash
  ./bin/op-node \
    --l1=$L1_RPC_URL \
    --l1.rpckind=$L1_RPC_KIND \
    --l2=ws://localhost:8551 \
    --l2.jwt-secret=./jwt.txt \
    --network=op-mainnet \
    --rpc.addr=0.0.0.0 \
    --rpc.port=8547
  ```

  <Callout>
    Some L1 nodes, like Erigon, do not support the `eth_getProof` RPC method that the `op-node` uses to load L1 data for certain processing steps.
    If you are using an L1 node that does not support `eth_getProof`, you will need to include the `--l1.trustrpc` flag when starting `op-node`.
    Note that this flag will cause `op-node` to trust the L1 node to provide correct data as it will no longer be able to independently verify the data it receives.
  </Callout>
</Steps>

## Synchronization

Once you've started `op-geth` and `op-node` you should see the two begin to communicate with each other and synchronize the OP Mainnet chain.
Initial synchronization can take several hours to complete.

During this time, you will initially observe `op-node` deriving blocks from Ethereum without sending these blocks to `op-geth`.
This means that `op-node` is requesting blocks from Ethereum one-by-one and determining the corresponding OP Mainnet blocks that were published to Ethereum.
You should see logs like the following from `op-node`:

```text
INFO [06-26|13:31:20.389] Advancing bq origin                      origin=17171d..1bc69b:8300332 originBehind=false
```

Once the `op-node` has derived enough blocks from Ethereum, it will begin sending these blocks to `op-geth`.
You should see logs like the following from `op-node`:

```text
INFO [06-26|14:00:59.460] Sync progress                            reason="processed safe block derived from L1" l2_finalized=ef93e6..e0f367:4067805 l2_safe=7fe3f6..900127:4068014 l2_unsafe=7fe3f6..900127:4068014 l2_time=1,673,564,096 l1_derived=6079cd..be4231:8301091
INFO [06-26|14:00:59.460] Found next batch                         epoch=8e8a03..11a6de:8301087 batch_epoch=8301087 batch_timestamp=1,673,564,098
INFO [06-26|14:00:59.461] generated attributes in payload queue    txs=1  timestamp=1,673,564,098
INFO [06-26|14:00:59.463] inserted block                           hash=e80dc4..72a759 number=4,068,015 state_root=660ced..043025 timestamp=1,673,564,098 parent=7fe3f6..900127 prev_randao=78e43d..36f07a fee_recipient=0x4200000000000000000000000000000000000011 txs=1  update_safe=true
```

You should then also begin to see logs like the following from `op-geth`:

```text
INFO [06-26|14:02:12.974] Imported new potential chain segment     number=4,068,194 hash=a334a0..609a83 blocks=1         txs=1         mgas=0.000  elapsed=1.482ms     mgasps=0.000   age=5mo2w20h dirty=2.31MiB
INFO [06-26|14:02:12.976] Chain head was updated                   number=4,068,194 hash=a334a0..609a83 root=e80f5e..dd06f9 elapsed="188.373µs" age=5mo2w20h
INFO [06-26|14:02:12.982] Starting work on payload                 id=0x5542117d680dbd4e
```

## Next Steps

*   If you've already got your node up and running, check out the [Node Metrics and Monitoring Guide](../management/metrics) to learn how to keep tabs on your node and make sure it keeps running smoothly.
*   If you run into any problems, please visit the [Node Troubleshooting Guide](../management/troubleshooting) for help.
